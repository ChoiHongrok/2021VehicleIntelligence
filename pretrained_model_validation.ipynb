{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nutritional-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch와 matplotlib 충돌 방지\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-slovenia",
   "metadata": {},
   "source": [
    "# image/label check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial-uniform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공식 ImageNet 홈페이지에서 다운받은 ImageNet2012 이미지 \n",
    "import os\n",
    "\n",
    "files = os.listdir('ILSVRC2012_img_val')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "## new labels\n",
    "## ImageNet에서 제공받은 label이 모델과 다르게 indexing 되어 있어\n",
    "## 새로운 label 파일을 다운받음 https://gist.github.com/ksimonyan/fd8800eeb36e276cd6f9#note\n",
    "\n",
    "with open('caffe_ilsvrc12.tar/val.txt') as f:\n",
    "    \n",
    "    text = f.read()\n",
    "\n",
    "labels = [int(label.split('JPEG')[1]) for label in text.split('\\n')[:-1]]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moral-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 999, 50000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0~999까지의 값을 갖는 label 5만개\n",
    "min(labels), max(labels), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-lesbian",
   "metadata": {},
   "source": [
    "# 현재 ImageNet에서 제공하는 label index와 torch에서 제공하는 pretrained model의 label index가 달라 맞추어주어야함\n",
    "# --> pretrained model에 맞는 label로 다시 매핑함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-bulgaria",
   "metadata": {},
   "source": [
    "# Make directory for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "inner-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a96fb3107ee447eb202a13b5f33a454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_path = 'ILSVRC2012_img_val'\n",
    "img_path = 'ImageNet_validation'\n",
    "\n",
    "#새로운 폴더 생성\n",
    "os.mkdir(img_path)\n",
    "\n",
    "#class 별 폴더 생성\n",
    "for i in range(1000):\n",
    "    os.mkdir(img_path+'/'+str(i))\n",
    "    \n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 만들어둔 class별 폴더로 이미지를 복사함\n",
    "for file, label in tqdm(zip(sorted(files), labels), total=50000):\n",
    "    \n",
    "    shutil.copyfile(original_path+'/'+file, img_path+'/'+str(label)+'/'+file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-barcelona",
   "metadata": {},
   "source": [
    "# DataLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dependent-tuning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 391)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# https://github.com/pytorch/examples/blob/42e5b996718797e45c46a25c55b031e6768f8440/imagenet/main.py#L89-L101\n",
    "# pytorch examples를 참조하여 전처리함\n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = T.Compose([T.Scale(256), \n",
    "                       T.CenterCrop(224), \n",
    "                       T.ToTensor(),\n",
    "                       normalize])\n",
    "\n",
    "# ImageFolder를 사용하여 데이터를 불러온 후 DataLoader로 변환\n",
    "val_data = torchvision.datasets.ImageFolder(root = img_path, transform=transform, )\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128, drop_last=False, shuffle=False)\n",
    "\n",
    "len(val_data), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-pittsburgh",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unable-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet\n",
    "# VGG16\n",
    "# ResNet18\n",
    "# GoogLeNet\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# pre-trained model 불러오기\n",
    "alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "googlenet = torchvision.models.googlenet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-newman",
   "metadata": {},
   "source": [
    "# Model evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "interested-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model):\n",
    "    \n",
    "    global evals, pred, label, img, pred_idx\n",
    "    \n",
    "    evals = []\n",
    "    model.eval()\n",
    "    class_to_idx = val_data.class_to_idx\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for img, label in tqdm(val_loader, total=len(val_loader)):\n",
    "            \n",
    "            #예측후 top1만 추출\n",
    "            pred = model(img)\n",
    "            pred = torch.max(pred, 1)[1]\n",
    "            \n",
    "            #원래 모델에 맞는 index로 바꾸어줌\n",
    "            pred_idx = [class_to_idx[str(p)] for p in pred.numpy()]\n",
    "            pred_idx = torch.tensor(pred_idx)\n",
    "            \n",
    "            # 평가\n",
    "            evals.append(np.array(pred_idx == label))\n",
    "            \n",
    "#             if len(evals) > 2:\n",
    "#                 break\n",
    "        \n",
    "    evals = np.concatenate(evals)\n",
    "    \n",
    "    return evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "popular-syndrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb52480d6184bbba9bb85e2502a4771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.56522"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_eval = evaluate(alexnet)\n",
    "\n",
    "alexnet_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "earlier-installation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet_eval']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(alexnet_eval, 'alexnet_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "disturbed-emerald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc05b02e69734f058c548b49a2371fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.71592"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_eval = evaluate(vgg16)\n",
    "\n",
    "vgg16_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "serial-equivalent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54df321b97324cd9bfc740abc0f19af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.69758"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18_eval = evaluate(resnet18)\n",
    "resnet18_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "indoor-marketplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vgg16_eval']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vgg16_eval, 'vgg16_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "close-story",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133c3647654d44dfbf2cafeefd522404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.69778"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googlenet_eval = evaluate(googlenet)\n",
    "googlenet_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "continuing-firewall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet18_eval']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(resnet18_eval, 'resnet18_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "antique-authority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['googlenet_eval']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(googlenet_eval, 'googlenet_eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-hybrid",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "later-shopper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-1 Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AlexNet</th>\n",
       "      <td>0.56522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG16</th>\n",
       "      <td>0.71592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResNet18</th>\n",
       "      <td>0.69758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoogleNet</th>\n",
       "      <td>0.69778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-1 Accuracy\n",
       "AlexNet           0.56522\n",
       "VGG16             0.71592\n",
       "ResNet18          0.69758\n",
       "GoogleNet         0.69778"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "alexnet_eval = joblib.load('alexnet_eval')\n",
    "vgg16_eval = joblib.load('vgg16_eval')\n",
    "resnet18_eval = joblib.load('resnet18_eval')\n",
    "googlenet_eval = joblib.load('googlenet_eval')\n",
    "\n",
    "\n",
    "pd.DataFrame(index=['AlexNet', 'VGG16', 'ResNet18', 'GoogleNet'],\n",
    "            columns=['Top-1 Accuracy'],\n",
    "            data = [[alexnet_eval.mean()],\n",
    "                      [vgg16_eval.mean()],\n",
    "                      [resnet18_eval.mean()],\n",
    "                      [googlenet_eval.mean()]\n",
    "                     ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
